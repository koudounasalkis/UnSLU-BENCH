{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_train_path = 'data_slurp/train.csv'\n",
    "df_train = pd.read_csv(df_train_path, index_col=None)\n",
    "\n",
    "df_test_path = 'data_slurp/test.csv'\n",
    "df_test = pd.read_csv(df_test_path, index_col=None)\n",
    "\n",
    "# get intent of train data\n",
    "intent_train = df_train['intent'].unique()\n",
    "print('Intent of train data: ', len(intent_train))\n",
    "\n",
    "# get intent of test data\n",
    "intent_test = df_test['intent'].unique()\n",
    "print('Intent of test data: ', len(intent_test))\n",
    "\n",
    "# remove from test data intents that are not in train data\n",
    "df_test = df_test[df_test['intent'].isin(intent_train)]\n",
    "\n",
    "# get intent of test data\n",
    "intent_test = df_test['intent'].unique()\n",
    "print('Intent of test data: ', len(intent_test))\n",
    "\n",
    "# save test data\n",
    "df_test.to_csv('data_slurp_unlearning/test_unlearning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def read_data(df_train_path, df_val_path):\n",
    "    df_train = pd.read_csv(df_train_path, index_col=None)\n",
    "    df_val = pd.read_csv(df_val_path, index_col=None)\n",
    "    \n",
    "    ##Â Prepare Labels\n",
    "    labels = df_train['intent'].unique()\n",
    "    label2id, id2label = dict(), dict()\n",
    "    for i, label in enumerate(labels):\n",
    "        label2id[label] = str(i)\n",
    "        id2label[str(i)] = label\n",
    "    num_labels = len(id2label)\n",
    "\n",
    "    ## Train\n",
    "    for index in range(0,len(df_train)):\n",
    "        df_train.loc[index,'label'] = label2id[df_train.loc[index, 'intent']]\n",
    "    df_train['label'] = df_train['label'].astype(int)\n",
    "\n",
    "    ## Validation\n",
    "    for index in range(0,len(df_val)):\n",
    "        df_val.loc[index,'label'] = label2id[df_val.loc[index, 'intent']]\n",
    "    df_val['label'] = df_val['label'].astype(int)\n",
    "\n",
    "    print(\"Label2Id: \", label2id)\n",
    "    print(\"Id2Label: \", id2label)\n",
    "    print(\"Num Labels: \", num_labels)\n",
    "\n",
    "    return df_train, df_val, num_labels, label2id, id2label, labels\n",
    "\n",
    "\n",
    "df_train, df_val, num_labels, label2id, id2label, labels = read_data(\n",
    "        \"data_slurp_unlearning/train_unlearning.csv\", \n",
    "        \"data_slurp_unlearning/val_unlearning.csv\", \n",
    "        )\n",
    "print(\"Num labels: \", num_labels)\n",
    "df_train, df_test, num_labels, label2id, id2label, labels = read_data(\n",
    "        \"data_slurp_unlearning/train_unlearning.csv\", \n",
    "        \"data_slurp_unlearning/test_unlearning.csv\", \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "# split by identities the dataset until the original numerosity of the datasets is reached\n",
    "# we will have 3 datasets, one for training, one for validation and one for testing\n",
    "\n",
    "df['speaker_id'] = df['speaker_id'].astype(str)\n",
    "identities = df['speaker_id'].unique()\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_val = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_identities = len(identities)\n",
    "for identity in identities: \n",
    "    df_identity = df[df['speaker_id'] == identity]\n",
    "    n_samples = len(df_identity)\n",
    "    # put identities in the training set until we reach 80% of the original dataset\n",
    "    if len(df_train) < 0.8 * len(df):\n",
    "        df_train = pd.concat([df_train, df_identity], ignore_index=True)\n",
    "    elif len(df_val) < 0.1 * len(df):\n",
    "        df_val = pd.concat([df_val, df_identity], ignore_index=True)\n",
    "    else:\n",
    "        df_test = pd.concat([df_test, df_identity], ignore_index=True)\n",
    "    \n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the three dataset are disjoint and don't have any common identity\n",
    "\n",
    "train_identities = df_train['speaker_id'].unique()\n",
    "val_identities = df_val['speaker_id'].unique()\n",
    "test_identities = df_test['speaker_id'].unique()\n",
    "\n",
    "for identity in train_identities:\n",
    "    assert identity not in val_identities\n",
    "    assert identity not in test_identities\n",
    "\n",
    "for identity in val_identities:\n",
    "    assert identity not in test_identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "import random\n",
    "\n",
    "def get_forget_retain_split(df_train, min_samples_forget=100, ratio=0.025, seed=0, speaker_col='speakerId'):\n",
    "\n",
    "    speakerids = df_train[speaker_col].value_counts()\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    # sample speakers that have at least 200 samples until 2.5% of the total dataset samples are reached\n",
    "    speakers = speakerids[speakerids>min_samples_forget].index.tolist()\n",
    "    total_samples = 0 \n",
    "    speakers_to_sample = []\n",
    "    while total_samples < len(df_train)*ratio:\n",
    "        speaker = random.choice(speakers)\n",
    "        speakers_to_sample.append(speaker)\n",
    "        total_samples += speakerids[speaker]\n",
    "\n",
    "    df_forget = df_train[df_train[speaker_col].isin(speakers_to_sample)]\n",
    "    df_retain = df_train[~df_train[speaker_col].isin(speakers_to_sample)]\n",
    "    return df_forget, df_retain\n",
    "\n",
    "speakerl_col = 'speaker_id'\n",
    "df_forget, df_retain = get_forget_retain_split(df_train, speaker_col=speakerl_col)\n",
    "\n",
    "assert len(df_forget) + len(df_retain) == len(df_train)\n",
    "assert len(set(df_forget[speakerl_col]).intersection(set(df_retain[speakerl_col]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_forget) / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count intent distribution in forget and retain datasets\n",
    "len(df_forget.intent.unique()), len(df_retain.intent.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forget.intent.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retain.intent.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the indexes in a txt file of the forget samples and the retain one \n",
    "# forget_indexes = df_forget.index.tolist()\n",
    "# retain_indexes = df_retain.index.tolist()\n",
    "\n",
    "# with open('forget_indexes.txt', 'w') as f:\n",
    "#     for item in forget_indexes:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "# with open('retain_indexes.txt', 'w') as f:\n",
    "#     for item in retain_indexes:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "speaker_ids_forget = np.unique(df_forget['speaker_id'])\n",
    "speaker_ids_forget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array(['ME-140', 'ME-144', 'MO-463'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove from val and test the speakers that are in the forget\n",
    "print(\"Before forget: \", len(df_val), len(df_test))\n",
    "df_val_forget = df_val[~df_val['speaker_id'].isin(speaker_ids_forget)]\n",
    "df_test_forget = df_test[~df_test['speaker_id'].isin(speaker_ids_forget)]\n",
    "print(\"After forget: \", len(df_val_forget), len(df_test_forget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the forget, retain, val and test\n",
    "import os \n",
    "folder = \"data_slurp_unlearning\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "df_forget.to_csv(os.path.join(folder, \"forget.csv\"), index=False)\n",
    "df_retain.to_csv(os.path.join(folder, \"retain.csv\"), index=False)\n",
    "# df_val_forget.to_csv(os.path.join(folder, \"val_forget.csv\"), index=False)\n",
    "# df_test_forget.to_csv(os.path.join(folder, \"test_forget.csv\"), index=False)\n",
    "# df_train.to_csv(os.path.join(folder, \"train.csv\"), index=False)\n",
    "# df_val.to_csv(os.path.join(folder, \"val.csv\"), index=False)\n",
    "# df_test.to_csv(os.path.join(folder, \"test.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
