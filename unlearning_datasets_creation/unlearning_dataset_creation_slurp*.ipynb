{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "df_train_path = 'data_slurp/train.csv'\n",
    "df_train = pd.read_csv(df_train_path, index_col=None)\n",
    "\n",
    "df_test_path = 'data_slurp/test.csv'\n",
    "df_test = pd.read_csv(df_test_path, index_col=None)\n",
    "\n",
    "intent_train = df_train['intent'].unique()\n",
    "print('Intent of train data: ', len(intent_train))\n",
    "\n",
    "intent_test = df_test['intent'].unique()\n",
    "print('Intent of test data: ', len(intent_test))\n",
    "\n",
    "df_test = df_test[df_test['intent'].isin(intent_train)]\n",
    "\n",
    "intent_test = df_test['intent'].unique()\n",
    "print('Intent of test data: ', len(intent_test))\n",
    "\n",
    "os.makedirs('data_slurp/', exist_ok=True)\n",
    "df_test.to_csv('data_slurp/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def read_data(df_train_path, df_val_path):\n",
    "    df_train = pd.read_csv(df_train_path, index_col=None)\n",
    "    df_val = pd.read_csv(df_val_path, index_col=None)\n",
    "    \n",
    "    labels = df_train['intent'].unique()\n",
    "    label2id, id2label = dict(), dict()\n",
    "    for i, label in enumerate(labels):\n",
    "        label2id[label] = str(i)\n",
    "        id2label[str(i)] = label\n",
    "    num_labels = len(id2label)\n",
    "\n",
    "    for index in range(0,len(df_train)):\n",
    "        df_train.loc[index,'label'] = label2id[df_train.loc[index, 'intent']]\n",
    "    df_train['label'] = df_train['label'].astype(int)\n",
    "\n",
    "    for index in range(0,len(df_val)):\n",
    "        df_val.loc[index,'label'] = label2id[df_val.loc[index, 'intent']]\n",
    "    df_val['label'] = df_val['label'].astype(int)\n",
    "\n",
    "    print(\"Label2Id: \", label2id)\n",
    "    print(\"Id2Label: \", id2label)\n",
    "    print(\"Num Labels: \", num_labels)\n",
    "\n",
    "    return df_train, df_val, num_labels, label2id, id2label, labels\n",
    "\n",
    "\n",
    "df_train, df_val, num_labels, label2id, id2label, labels = read_data(\n",
    "        \"data_slurp/train.csv\", \n",
    "        \"data_slurp/val.csv\", \n",
    "        )\n",
    "print(\"Num labels: \", num_labels)\n",
    "df_train, df_test, num_labels, label2id, id2label, labels = read_data(\n",
    "        \"data_slurp/train.csv\", \n",
    "        \"data_slurp/test.csv\", \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "# split by identities the dataset until the original numerosity of the datasets is reached\n",
    "# we will have 3 datasets, one for training, one for validation and one for testing\n",
    "\n",
    "df['speaker_id'] = df['speaker_id'].astype(str)\n",
    "identities = df['speaker_id'].unique()\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_val = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_identities = len(identities)\n",
    "for identity in identities: \n",
    "    df_identity = df[df['speaker_id'] == identity]\n",
    "    n_samples = len(df_identity)\n",
    "    # put identities in the training set until we reach 80% of the original dataset\n",
    "    if len(df_train) < 0.8 * len(df):\n",
    "        df_train = pd.concat([df_train, df_identity], ignore_index=True)\n",
    "    elif len(df_val) < 0.1 * len(df):\n",
    "        df_val = pd.concat([df_val, df_identity], ignore_index=True)\n",
    "    else:\n",
    "        df_test = pd.concat([df_test, df_identity], ignore_index=True)\n",
    "    \n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the three dataset are disjoint and don't have any common identity\n",
    "\n",
    "train_identities = df_train['speaker_id'].unique()\n",
    "val_identities = df_val['speaker_id'].unique()\n",
    "test_identities = df_test['speaker_id'].unique()\n",
    "\n",
    "for identity in train_identities:\n",
    "    assert identity not in val_identities\n",
    "    assert identity not in test_identities\n",
    "\n",
    "for identity in val_identities:\n",
    "    assert identity not in test_identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "import random\n",
    "\n",
    "def get_forget_retain_split(df_train, min_samples_forget=100, ratio=0.025, seed=0, speaker_col='speakerId'):\n",
    "\n",
    "    speakerids = df_train[speaker_col].value_counts()\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    # sample speakers that have at least 200 samples until 2.5% of the total dataset samples are reached\n",
    "    speakers = speakerids[speakerids>min_samples_forget].index.tolist()\n",
    "    total_samples = 0 \n",
    "    speakers_to_sample = []\n",
    "    while total_samples < len(df_train)*ratio:\n",
    "        speaker = random.choice(speakers)\n",
    "        speakers_to_sample.append(speaker)\n",
    "        total_samples += speakerids[speaker]\n",
    "\n",
    "    df_forget = df_train[df_train[speaker_col].isin(speakers_to_sample)]\n",
    "    df_retain = df_train[~df_train[speaker_col].isin(speakers_to_sample)]\n",
    "    return df_forget, df_retain\n",
    "\n",
    "speakerl_col = 'speaker_id'\n",
    "df_forget, df_retain = get_forget_retain_split(df_train, speaker_col=speakerl_col)\n",
    "\n",
    "assert len(df_forget) + len(df_retain) == len(df_train)\n",
    "assert len(set(df_forget[speakerl_col]).intersection(set(df_retain[speakerl_col]))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_forget) / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count intent distribution in forget and retain datasets\n",
    "len(df_forget.intent.unique()), len(df_retain.intent.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forget.intent.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retain.intent.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "speaker_ids_forget = np.unique(df_forget['speaker_id'])\n",
    "speaker_ids_forget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before forget: \", len(df_val), len(df_test))\n",
    "df_val_forget = df_val[~df_val['speaker_id'].isin(speaker_ids_forget)]\n",
    "df_test_forget = df_test[~df_test['speaker_id'].isin(speaker_ids_forget)]\n",
    "print(\"After forget: \", len(df_val_forget), len(df_test_forget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data_slurp*/\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "df_forget.to_csv(os.path.join(folder, \"forget.csv\"), index=False)\n",
    "df_retain.to_csv(os.path.join(folder, \"retain.csv\"), index=False)\n",
    "df_train.to_csv(os.path.join(folder, \"train.csv\"), index=False)\n",
    "df_val_forget.to_csv(os.path.join(folder, \"val.csv\"), index=False)\n",
    "df_test_forget.to_csv(os.path.join(folder, \"test.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
